{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6795146-6efa-4e3e-8273-ddf392461333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  langchain langchain-community langchainhub langchain-openai chromadb bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3902fbb4-a866-46e2-871a-1b150a6cdc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "os.environ['USER_AGENT']='ProfessorAgent'\n",
    "\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a8fa91e-54a7-4f76-8f1a-04205ef6caa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Vald\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "raw_documents = TextLoader(\"../data/data.txt\").load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=3000, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0414236e-c636-48a0-beb0-e9987db5254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dbbb7a7-bfed-4e82-a0f8-a59626fb1da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324993"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2f86686-6b14-4f73-b1c0-607e9097f85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tion virtualization because I will come back to this once I explained Holograms and volumetric media delivery then I will also Explain how virtual Network functions can be of interest so if we consider a home environments then there are multiple devices and in your home and typically there is a home Gateway. And on the home K3, we have different functionality. There is the HTTP server. There is an entity router firewall also quality of experience monitoring software for instance. if we have TV streams or video streams that we display on screens inside your home then we also monitor the quality of experience inside the home Gateway. And then typical Auto device is a setup box. so stb. Which contains? for a digital TV storage so that you can record movies and TV programs. Middleware that allows you to interact through remote control. And to start recording stop recording play a certain TV program. and so on for unless we need to middleware on the setup box. And also we have a streaming client. So this is the software that starts streaming the files and make sure that we can see the videos on the screen. so if you look at these functionalities on the home Gateway and Books, these are typically called Network functions. And when they are executed on these boxes Then they are executed inside your homes. but if we virtualize them so virtualized Network functions vnfs then They will be. executed not in your home, but in a remote Data Center. and the data center can be close by but can also be far away and another country, but then we software rise this this functions and and they run as software components inside remote Data Center. And this is a very important Evolution because then we don't need these devices in your home. You just need to connect the different screens. to the network sockets so that they have internet connectivity, but but all the other functions that are listed here. They are no longer executed inside your home. and there are many advantages first from point of view of a network operator. Because we can maximize resource utilization. and also optimize energy usage because if all the functions they run on separate devices in each home. They need to run permanently. but if if they are in a data center then we can run many of them on on the same machine. making use of virtual machines or containers inside the data center. and also in terms of Updates, this is a very important Advantage when we update Network functions, then we can very fast and easy deploy them. And and configure them. and it's much easier than changing software on a dedicated device at home in a data center. We can overnight quickly and efficiently updates Network functions. And also for the service provider there are many advantages. Which are listed here. so we can dynamically scale Network and Computing and storage resources. based on on service requirements. so we can make use of elasticity properties of cloud computing. and we have a reduced time to market for se\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[5000:8000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cffff3fb-443b-4129-97fb-34fb2fa8af3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "db = DocArrayInMemorySearch.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e623107-eaa9-4e0c-9da9-bb87caf9d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05265df2-f7f7-4f18-a73c-aee55b719e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "daf54f0a-38b9-42d0-9247-630cdee34d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0, model=\"gpt-3.5-turbo\", max_tokens=2048)\n",
    "db = DocArrayInMemorySearch.from_documents(\n",
    "    all_splits,\n",
    "    embeddings\n",
    ")\n",
    "retriever = db.as_retriever()\n",
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab57fd54-2851-48e2-8e9d-8bece5d8f3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "@tool\n",
    "def find_seminar_quote(text: str) -> str:\n",
    "    \"\"\" Receives a question from the user about a seminar and returns a description of it from the transcript.\n",
    "    \"\"\"\n",
    "\n",
    "    query =  f\"\"\"Please gather more information about '''{text}''' and summarize the output\"\"\"\n",
    "    response = qa_stuff.run(query)\n",
    "    \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "772ae1eb-5423-4783-8a48-ff3916dfe78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/Desktop/Projects/seminars-agent/env/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tools=[find_seminar_quote]\n",
    "tools = tools # +  [TavilySearchResults(max_results=1)]# + load_tools([\"wikipedia\"], llm=llm)\n",
    "agent= initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b3fb817-0175-44f3-a124-5b2c47ebfa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/Desktop/Projects/seminars-agent/env/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I should use the `find_seminar_quote` tool to gather information on the most efficient technique to prompt an LLM.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"find_seminar_quote\",\n",
      "  \"action_input\": \"most efficient technique to prompt an LLM\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/Desktop/Projects/seminars-agent/env/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mI don't have enough information to provide a specific answer to your question about the most efficient technique to prompt an LLM. The context provided discusses the importance of formatting or prompting engineering in optimizing code and utilizing autocomplete systems effectively. It mentions the use of demonstrations, chaining thoughts, and editing to enhance the efficiency of prompting. Additionally, it suggests avoiding training your own base models and utilizing cloud APIs for instruction tuning. If you are interested in exploring this topic further, you may want to look into the GitHub repository mentioned in the context for more detailed information.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Final Answer\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3mI will try using the `find_seminar_quote` tool again to gather more information on the most efficient technique to prompt an LLM.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"find_seminar_quote\",\n",
      "  \"action_input\": \"efficient technique to prompt an LLM\"\n",
      "}\n",
      "``` \n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mI don't have enough information to provide a summary on the efficient technique to prompt an LLM based on the context provided.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI will try a different approach to gather information on the most efficient technique to prompt an LLM.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"find_seminar_quote\",\n",
      "  \"action_input\": \"efficient technique to prompt a language model\"\n",
      "}\n",
      "``` \n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe efficient technique to prompt a language model involves using few-shot prompting, which is more effective than explaining a problem in detail. Few-shot prompting entails providing 50 demonstrations to the model to help it understand patterns and examples better. Additionally, instruction tuning can be used as a more expensive but effective tool to further refine the model's performance. It is recommended to start with few-shot prompting before considering instruction tuning. This technique helps in turning a completion system into a conversational AI by tricking the model into believing it is engaged in a conversation. The process involves updating the model through methods like supervised fine-tuning and reinforcement learning. Despite the advancements in AI models like fancy autocomplete, there are still unanswered questions about how these models excel in certain tasks while making mistakes in others.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: The most efficient technique to prompt a language model involves using few-shot prompting and instruction tuning to enhance the model's performance.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Based on what you know what is the most efficient techinique to prompt an llm?',\n",
       " 'output': \"The most efficient technique to prompt a language model involves using few-shot prompting and instruction tuning to enhance the model's performance.\"}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"Based on what you know what is the most efficient techinique to prompt an llm?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "804f1816-890b-4745-9771-b30dcea1ef67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: This question seems to be asking about the transmission of holograms in networks. I should use the find_seminar_quote tool to see if there is any relevant information in the seminar transcript.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"find_seminar_quote\",\n",
      "  \"action_input\": \"holograms sent in networks\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mBased on the provided context, holograms being sent over networks require high bandwidth, on the order of gigabits per second. This is due to the complex data involved in holographic communications. Two important technologies for transmitting holograms are Point Clouds and Light Fields. Point Clouds involve representing objects by considering all possible points in three-dimensional space, while Light Fields technology is expected to be important in the future for modeling environments as well as objects. The bandwidth requirements for transmitting video over networks vary depending on the quality, ranging from up to 5 megabits per second for high definition television to 500 megabits per second for 16k resolution. Compression techniques are essential for transporting holographic data efficiently over networks. The context also mentions ongoing European projects like the SPIRIT project involving partners like Deutsche Telekom and Ericsson, focusing on network optimizations and holographic communications.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Final Answer\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3mI made a mistake in my previous response. Let me try again to provide a relevant excerpt from the seminar transcript regarding the transmission of holograms in networks.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"find_seminar_quote\",\n",
      "  \"action_input\": \"holograms in networks\"\n",
      "}\n",
      "``` \n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mI don't have enough information to provide a summary on holograms in networks based on the context provided.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI will try to find a relevant excerpt from the seminar transcript regarding the transmission of holograms in networks.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"find_seminar_quote\",\n",
      "  \"action_input\": \"holograms in networks\"\n",
      "}\n",
      "``` \n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mBased on the provided context, holograms in networks refer to the transmission of volumetric media, such as holographic images or videos, over communication networks. This technology requires high bandwidth, with requirements in the order of gigabits per second for transporting holographic data. To address this challenge, compression techniques are essential to enable the efficient transmission of holograms over networks.\n",
      "\n",
      "The use of holograms in networks has various applications across different domains, including healthcare, retail, education, training, entertainment, manufacturing, industry 4.0, and tourism. The Spirit project, a European initiative involving partners like Deutsche Telekom and Ericsson, aims to explore and demonstrate the potential of holographic communications in these application areas.\n",
      "\n",
      "Overall, the transmission of holograms over networks presents significant challenges in terms of bandwidth requirements and network infrastructure capabilities. Research and collaboration between industry, academia, and researchers are crucial to optimize network performance, develop compression techniques, and address the technical and practical aspects of holographic communications for future applications.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Final Answer\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Final Answer\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Final Answer\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Final Answer\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Final Answer\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Final Answer\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Final Answer\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Final Answer\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Final Answer\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Final Answer\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: The transmission of holograms in networks requires high bandwidth, on the order of gigabits per second, and compression techniques are essential for efficient data transport. Holograms in networks involve volumetric media like holographic images or videos and have applications in various sectors. The Spirit project in Europe explores holographic communications' potential in areas such as healthcare, retail, education, entertainment, and more.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How holograms will be sent in our networks?',\n",
       " 'output': \"The transmission of holograms in networks requires high bandwidth, on the order of gigabits per second, and compression techniques are essential for efficient data transport. Holograms in networks involve volumetric media like holographic images or videos and have applications in various sectors. The Spirit project in Europe explores holographic communications' potential in areas such as healthcare, retail, education, entertainment, and more.\"}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"How holograms will be sent in our networks?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00b22ed-68e9-4e21-ae57-1cf4b8d3bb32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
